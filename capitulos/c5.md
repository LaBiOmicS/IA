# Cap√≠tulo 5 ‚Äì Ecossistema Python para Data Science e ML

## 5.0 Introdu√ß√£o

Ao longo dos cap√≠tulos anteriores, aprendemos os fundamentos de Python, l√≥gica de programa√ß√£o e estat√≠stica.  
Agora, entramos em uma etapa crucial: conhecer o **ecossistema de bibliotecas cient√≠ficas** que transformou o Python em uma das linguagens mais populares para **ci√™ncia de dados, bioinform√°tica e aprendizado de m√°quina**.

### Por que usar bibliotecas?
- **Evitar reinventar a roda:** problemas complexos j√° foram resolvidos e otimizados pela comunidade cient√≠fica.  
- **Performance:** embora Python puro seja flex√≠vel, suas listas e la√ßos n√£o s√£o eficientes para c√°lculos num√©ricos intensos; bibliotecas como **NumPy** usam implementa√ß√µes em C/Fortran altamente otimizadas.  
- **Confiabilidade:** bibliotecas amplamente utilizadas foram testadas por milhares de pesquisadores, garantindo resultados robustos.  
- **Produtividade:** poucas linhas de c√≥digo resolvem tarefas que exigiriam dezenas em Python puro.  

### A l√≥gica do ecossistema
Cada biblioteca cobre uma etapa espec√≠fica do fluxo de trabalho em ci√™ncia de dados e ML:

1. **Coleta de dados:** com **BeautifulSoup**, podemos extrair informa√ß√µes de p√°ginas da web (not√≠cias de sa√∫de, bases p√∫blicas, relat√≥rios).  
2. **N√∫meros e arrays:** com **NumPy**, manipulamos matrizes de express√£o g√™nica, sinais biom√©dicos e imagens m√©dicas de forma eficiente.  
3. **Ferramentas cient√≠ficas:** o **SciPy** oferece estat√≠stica, otimiza√ß√£o, integra√ß√£o e an√°lise de sinais (essencial para PPG, ECG, EEG).  
4. **Dados tabulares:** o **Pandas** organiza dados cl√≠nicos, metadados de sequenciamento ou prontu√°rios eletr√¥nicos em tabelas.  
5. **Visualiza√ß√£o:** **Matplotlib** (baixo n√≠vel, customiz√°vel) e **Seaborn** (alto n√≠vel, estat√≠stico) permitem comunicar resultados com clareza.  
6. **Modelagem:** o **Scikit-learn** fornece algoritmos de aprendizado supervisionado e n√£o supervisionado, pipelines e valida√ß√£o cruzada.  

### Exemplo narrativo
Imagine um projeto de bioinform√°tica ou inform√°tica biom√©dica:
- Primeiro, coletamos **t√≠tulos de artigos sobre diabetes** do site da OMS usando **BeautifulSoup**.  
- Em seguida, transformamos esses dados em **estruturas num√©ricas com NumPy**.  
- Aplicamos testes estat√≠sticos com **SciPy**.  
- Organizamos dados cl√≠nicos dos pacientes em um **DataFrame do Pandas**.  
- Visualizamos padr√µes de glicemia e colesterol com **Seaborn**.  
- Por fim, treinamos um modelo preditivo no **Scikit-learn** para identificar risco de diabetes.  

### Objetivo do cap√≠tulo
Apresentar, de forma did√°tica e detalhada, cada biblioteca essencial para ci√™ncia de dados com Python, sempre contextualizando exemplos em **sa√∫de, biomedicina e bioinform√°tica**.  
Cada se√ß√£o trar√° conceitos, exemplos pr√°ticos e **exerc√≠cios** para fixa√ß√£o, preparando o leitor para projetos reais.

---

# Cap√≠tulo 5 ‚Äì Ecossistema Python para Data Science e ML

## 5.1 BeautifulSoup ‚Äî Coleta de dados na Web (Web Scraping)

### 5.1.1 Introdu√ß√£o
Quando voc√™ acessa uma p√°gina da web, como uma not√≠cia da OMS ou um artigo cient√≠fico no PubMed, o navegador recebe um **arquivo HTML** cheio de tags, atributos e textos.  
Esse HTML √© como um **manual de instru√ß√µes**: diz onde est√° o t√≠tulo, o par√°grafo, o link.  
Mas para n√≥s cientistas de dados, ele n√£o √© imediatamente √∫til.

O **BeautifulSoup** √© a biblioteca Python que **transforma HTML cru em uma estrutura naveg√°vel**.  
Com ele, podemos **extrair t√≠tulos, tabelas, links e metadados** e organizar em DataFrames.

üëâ Pense no BeautifulSoup como um **microsc√≥pio digital**: ele n√£o cria os dados, mas revela estruturas escondidas no HTML.

---

### 5.1.2 Por que usar o BeautifulSoup?
- **Facilidade**: encontra tags e atributos em poucas linhas.  
- **Toler√¢ncia**: lida com HTML ‚Äúbagun√ßado‚Äù.  
- **Integra√ß√£o**: sa√≠da (listas/dicion√°rios) pode ser convertida direto em Pandas.  

Aplica√ß√µes t√≠picas:  
- Coletar **t√≠tulos e resumos** de artigos cient√≠ficos.  
- Extrair **tabelas** de relat√≥rios p√∫blicos (OMS, minist√©rios).  
- Montar bases r√°pidas para **revis√µes sistem√°ticas**.

---

### 5.1.3 Estrutura b√°sica (DOM e conceitos)
- **HTML**: linguagem que estrutura uma p√°gina.  
- **DOM**: √°rvore de elementos HTML.  
- **Tag**: bloco (`<h1>`, `<p>`, `<table>`).  
- **Atributo**: informa√ß√£o extra (`class`, `id`, `href`).  
- **Texto**: conte√∫do dentro da tag.  
- **Navega√ß√£o**: pais (`parent`), filhos (`children`), irm√£os (`sibling`).  

üëâ Imagine o HTML como uma **√°rvore geneal√≥gica**: cada tag √© um parente com atributos.

---

### 5.1.4 Principais fun√ß√µes
- **Por tag**: `soup.find("h1")`, `soup.find_all("h2")`  
- **Por atributo**: `soup.find("a", class_="artigo")`  
- **Por CSS**: `soup.select("ul#lista li.artigo a")`  
- **Texto limpo**: `tag.get_text(strip=True)`  
- **Links**: `tag.get("href")`  

---

### 5.1.5 Exemplos pr√°ticos

#### Exemplo A ‚Äî HTML fict√≠cio
```python
from bs4 import BeautifulSoup

html = """
<ul id="lista">
  <li class="artigo"><a href="/artigo1">Predi√ß√£o de risco de diabetes</a></li>
  <li class="artigo"><a href="/artigo2">Marcadores gen√¥micos em c√¢ncer</a></li>
</ul>
"""

soup = BeautifulSoup(html, "html.parser")
for li in soup.find_all("li", class_="artigo"):
    titulo = li.get_text(strip=True)
    link = li.a["href"]
    print(titulo, "->", link)
```

Sa√≠da:
```
Predi√ß√£o de risco de diabetes -> /artigo1
Marcadores gen√¥micos em c√¢ncer -> /artigo2
```

---

#### Exemplo B ‚Äî Caso real (OMS)
```python
import requests
from bs4 import BeautifulSoup

url = "https://www.who.int/news"
resp = requests.get(url)
soup = BeautifulSoup(resp.text, "html.parser")

titulos = [h3.get_text(strip=True) for h3 in soup.select("a.link-container h3")]
print(titulos[:5])
```

---

#### Exemplo C ‚Äî DataFrame com Pandas
```python
import pandas as pd
df = pd.DataFrame({"titulo": titulos})
print(df.head())
```

---

#### Exemplo D ‚Äî Extraindo tabelas
```python
html = """
<table>
  <tr><th>Paciente</th><th>Glicemia</th></tr>
  <tr><td>A</td><td>120</td></tr>
  <tr><td>B</td><td>150</td></tr>
</table>
"""

soup = BeautifulSoup(html, "html.parser")
linhas = []
for tr in soup.find_all("tr")[1:]:
    tds = tr.find_all("td")
    linhas.append({"paciente": tds[0].text, "glicemia": int(tds[1].text)})
```

---

### 5.1.6 Boas pr√°ticas
- Respeite `robots.txt` e termos do site.  
- N√£o abuse: use `time.sleep(1)` entre requisi√ß√µes.  
- Prefira **APIs oficiais** quando houver.  
- Nunca colete dados pessoais (LGPD).  
- Salve o HTML original para reprodutibilidade.  

---

### 5.1.7 Erros comuns
- **`NoneType`**: seletor n√£o encontrou nada.  
- **Conte√∫do din√¢mico**: se for carregado via JS, BeautifulSoup n√£o v√™.  
- **Encoding errado**: for√ßar `resp.encoding = "utf-8"`.  
- **Seletores fr√°geis**: mudan√ßas no CSS do site podem quebrar o scraper.  

---

### 5.1.8 Exerc√≠cios ‚Äî BeautifulSoup

1. Extraia os **t√≠tulos das √∫ltimas not√≠cias** da OMS ([https://www.who.int/news](https://www.who.int/news)) e salve em CSV.  
2. No **PubMed**, busque ‚Äúdiabetes‚Äù (p√°gina HTML) e extraia t√≠tulos e links.  
3. Crie uma fun√ß√£o `get_links(html, seletor)` que retorna uma lista de URLs.  
4. Extraia uma **tabela cl√≠nica** de HTML fict√≠cio e converta para DataFrame.  
5. Crie `get_text_or_none(tag, sel)` que retorna texto ou `None`.  
6. Capture **manchetes e links** da se√ß√£o de Sa√∫de de um portal brasileiro.  
7. Adapte para lidar com **pagina√ß√£o** (`?page=1..N`).  
8. Salve resultados em **CSV** e **JSON** e explique diferen√ßas.  
9. Escreva **5 regras de √©tica em scraping** de sa√∫de e justifique.  
10. Mini-projeto: colete 10 not√≠cias da OMS, limpe duplicatas e exporte em `utf-8-sig`.  

---

## 5.2 NumPy ‚Äî Arrays, Vetoriza√ß√£o e Broadcasting

### 5.2.1 Introdu√ß√£o
O **NumPy** √© o alicerce num√©rico do ecossistema cient√≠fico em Python. Ele fornece o tipo `ndarray` (vetores e matrizes homog√™neos) e opera√ß√µes **vetorizadas** muito mais r√°pidas do que la√ßos puros em Python. Em bioinform√°tica e inform√°tica biom√©dica, √© onipresente: manipula√ß√£o de **matrizes de express√£o g√™nica**, **imagens m√©dicas** (como matrizes 2D/3D) e prepara√ß√£o de dados para modelos.

**Quando usar:** sempre que voc√™ precisar de **c√°lculo num√©rico intenso**, opera√ß√µes matriciais, estat√≠stica b√°sica eficiente ou transformar dados tabulares em arranjos num√©ricos para ML.

---

### 5.2.2 Conceitos‚Äëchave
- **`ndarray`**: container N‚Äëdimensional de dados homog√™neos (mesmo `dtype`).
- **`shape`**: tupla com o tamanho de cada dimens√£o, ex.: `(n_amostras, n_variaveis)`.
- **`dtype`**: tipo (ex.: `float64`, `int32`, `bool`).
- **Vetoriza√ß√£o**: operar de uma vez sobre todo o array (sem `for` expl√≠cito).
- **Broadcasting**: regras para operar arrays com formas diferentes, expandindo dimens√µes quando poss√≠vel.
- **Views vs Copies**: *slices* retornam vis√µes; alterar uma *view* pode afetar o original.

---

### 5.2.3 Criando e inspecionando arrays
```python
import numpy as np

# Vetores e matrizes
v = np.array([1, 2, 3], dtype=np.float64)
M = np.array([[1, 2, 3],
              [4, 5, 6]], dtype=np.int32)

# Arrays especiais
z = np.zeros((3, 4))        # zeros
o = np.ones((2, 2))         # ones
i = np.eye(3)               # identidade
r = np.arange(0, 10, 2)     # 0,2,4,6,8
u = np.linspace(0, 1, 5)    # 0. ,0.25,0.5,0.75,1.

print(v.shape, M.shape, z.dtype)
```

---

### 5.2.4 Indexa√ß√£o, *slicing* e m√°scaras
```python
import numpy as np
A = np.arange(12).reshape(3, 4)  # [[0..3],[4..7],[8..11]]

# Indexacao
print(A[0, 2])    # elemento (linha 0, col 2)
print(A[1])       # linha 1 inteira

# Slicing (view)
B = A[:, 1:3]     # colunas 1 e 2 de todas as linhas (view)
B[0, 0] = -99     # altera A tambem!

# Mascara booleana
mask = A > 5
sel = A[mask]
```

> **Importante:** use `A.copy()` quando precisar de **copia** independente.

---

### 5.2.5 Operacoes vetorizadas e broadcasting
```python
import numpy as np
X = np.array([[1., 2., 3.],
              [4., 5., 6.]])          # shape (2,3)
b = np.array([10., 20., 30.])         # shape (3,)

# Broadcasting soma b a cada linha de X
Y = X + b

# Normalizacao por coluna: (X - media) / desvio
mu = X.mean(axis=0)
sd = X.std(axis=0, ddof=0)
Z = (X - mu) / sd
```

---

### 5.2.6 Estatistica basica eficiente
```python
import numpy as np
glic = np.array([90, 110, 150, 130, 85, 120], dtype=np.float64)

media = glic.mean()
mediana = np.median(glic)
variancia = glic.var(ddof=0)  # populacional
desvio = glic.std(ddof=0)

p90 = np.percentile(glic, 90)
```

---

### 5.2.7 Algebra linear essencial (`numpy.linalg`)
```python
import numpy as np

A = np.array([[3., 1.],
              [2., 4.]])
b = np.array([7., 10.])

# Resolver Ax = b
x = np.linalg.solve(A, b)

# Autovalores/autovetores
w, V = np.linalg.eig(A)

# Decomposicao SVD
U, S, VT = np.linalg.svd(A)
```

Aplicacoes tipicas: reducao de dimensionalidade, regularizacao, filtros em imagens.

---

### 5.2.8 Aleatoriedade controlada (`numpy.random`/`Generator`)
```python
import numpy as np
rng = np.random.default_rng(42)

# Amostras
norm = rng.normal(loc=0.0, scale=1.0, size=1000)
binom = rng.binomial(n=10, p=0.3, size=1000)

# Permutacao embaralhada
x = np.arange(10)
rng.shuffle(x)    # in-place
```

> **Reprodutibilidade:** defina uma **semente** (ex.: `default_rng(42)`).

---

### 5.2.9 Exemplo biom√©dico ‚Äî normalizacao z‚Äëscore por gene
```python
import numpy as np

# Matriz de expressao: amostras x genes
expr = np.array([
    [5.2, 3.1, 8.0],
    [6.5, 2.9, 9.1],
    [4.8, 3.3, 7.5]
], dtype=np.float64)

mu = expr.mean(axis=0)         # media por gene (coluna)
sd = expr.std(axis=0, ddof=0)
expr_z = (expr - mu) / sd
```

---

### 5.2.10 Boas praticas e erros comuns
**Boas praticas**
- Prefira **vetoriza√ß√£o** a la√ßos; use *masking* em vez de `for`.
- Converta dados numericos para `float` quando houver divisao/NaN.
- Padronize **unidades** e **shapes** das entradas (documente).

**Erros comuns**
- **Broadcasting inesperado**: confirme `shape` antes da operacao.
- **`Setting values on a view`**: modifique copias quando nao quiser efeito colateral (`arr.copy()`).
- **Overflow/underflow**: cuidado com `dtype` (ex.: `float32` vs `float64`).

---

### 5.2.11 Exercicios ‚Äî NumPy
1. Crie uma matriz `n x m` (n>=5, m>=3) de dados clinicos (float) e: media, desvio, min/max por coluna.  
2. Aplique **z-score por coluna** e verifique que a media ~ 0 e desvio ~ 1.  
3. Usando **mascara**, selecione amostras com a coluna 0 acima do percentil 90.  
4. Simule uma imagem 2D (matriz 256x256) e normalize os pixels para [0,1].  
5. Resolva `Ax=b` para uma matriz 3x3 aleatoria e discuta condicao numerica (pelo `np.linalg.cond`).  
6. Gere 10.000 amostras de `Normal(120, 15)` (pressao sistolica) e compute percentis 5/50/95.  
7. Compare tempo de um `for` puro somando 1 a 1e7 elementos vs `arr + 1` (use `%timeit` no Jupyter).  
8. Implemente uma **padronizacao robusta**: subtrair mediana e dividir pelo IQR (Q3-Q1).  
9. Reproduza o **broadcasting** de soma linha‚Äëa‚Äëlinha e explique as regras envolvidas.  
10. Decomponha uma matriz com **SVD** e reconstrua‚Äëa a partir de `U @ np.diag(S) @ VT`; me√ßa o erro de reconstrucao.

---

## üîô Navega√ß√£o
- ‚¨ÖÔ∏è [Voltar ao Sum√°rio do Curso](../README.md)
