# Cap√≠tulo 5 ‚Äì Ecossistema Python para Data Science e ML

## 5.1 BeautifulSoup ‚Äî Coleta de dados na Web (Web Scraping)

### 5.1.1 Introdu√ß√£o
Quando voc√™ acessa uma p√°gina da web, como uma not√≠cia da OMS ou um artigo cient√≠fico no PubMed, o navegador recebe um **arquivo HTML** cheio de tags, atributos e textos.  
Esse HTML √© como um **manual de instru√ß√µes**: diz onde est√° o t√≠tulo, o par√°grafo, o link.  
Mas para n√≥s cientistas de dados, ele n√£o √© imediatamente √∫til.

O **BeautifulSoup** √© a biblioteca Python que **transforma HTML cru em uma estrutura naveg√°vel**.  
Com ele, podemos **extrair t√≠tulos, tabelas, links e metadados** e organizar em DataFrames.

üëâ Pense no BeautifulSoup como um **microsc√≥pio digital**: ele n√£o cria os dados, mas revela estruturas escondidas no HTML.

---

### 5.1.2 Por que usar o BeautifulSoup?
- **Facilidade**: encontra tags e atributos em poucas linhas.  
- **Toler√¢ncia**: lida com HTML ‚Äúbagun√ßado‚Äù.  
- **Integra√ß√£o**: sa√≠da (listas/dicion√°rios) pode ser convertida direto em Pandas.  

Aplica√ß√µes t√≠picas:  
- Coletar **t√≠tulos e resumos** de artigos cient√≠ficos.  
- Extrair **tabelas** de relat√≥rios p√∫blicos (OMS, minist√©rios).  
- Montar bases r√°pidas para **revis√µes sistem√°ticas**.

---

### 5.1.3 Estrutura b√°sica (DOM e conceitos)
- **HTML**: linguagem que estrutura uma p√°gina.  
- **DOM**: √°rvore de elementos HTML.  
- **Tag**: bloco (`<h1>`, `<p>`, `<table>`).  
- **Atributo**: informa√ß√£o extra (`class`, `id`, `href`).  
- **Texto**: conte√∫do dentro da tag.  
- **Navega√ß√£o**: pais (`parent`), filhos (`children`), irm√£os (`sibling`).  

üëâ Imagine o HTML como uma **√°rvore geneal√≥gica**: cada tag √© um parente com atributos.

---

### 5.1.4 Principais fun√ß√µes
- **Por tag**: `soup.find("h1")`, `soup.find_all("h2")`  
- **Por atributo**: `soup.find("a", class_="artigo")`  
- **Por CSS**: `soup.select("ul#lista li.artigo a")`  
- **Texto limpo**: `tag.get_text(strip=True)`  
- **Links**: `tag.get("href")`  

---

### 5.1.5 Exemplos pr√°ticos

#### Exemplo A ‚Äî HTML fict√≠cio
```python
from bs4 import BeautifulSoup

html = """
<ul id="lista">
  <li class="artigo"><a href="/artigo1">Predi√ß√£o de risco de diabetes</a></li>
  <li class="artigo"><a href="/artigo2">Marcadores gen√¥micos em c√¢ncer</a></li>
</ul>
"""

soup = BeautifulSoup(html, "html.parser")
for li in soup.find_all("li", class_="artigo"):
    titulo = li.get_text(strip=True)
    link = li.a["href"]
    print(titulo, "->", link)
```

Sa√≠da:
```
Predi√ß√£o de risco de diabetes -> /artigo1
Marcadores gen√¥micos em c√¢ncer -> /artigo2
```

---

#### Exemplo B ‚Äî Caso real (OMS)
```python
import requests
from bs4 import BeautifulSoup

url = "https://www.who.int/news"
resp = requests.get(url)
soup = BeautifulSoup(resp.text, "html.parser")

titulos = [h3.get_text(strip=True) for h3 in soup.select("a.link-container h3")]
print(titulos[:5])
```

---

#### Exemplo C ‚Äî DataFrame com Pandas
```python
import pandas as pd
df = pd.DataFrame({"titulo": titulos})
print(df.head())
```

---

#### Exemplo D ‚Äî Extraindo tabelas
```python
html = """
<table>
  <tr><th>Paciente</th><th>Glicemia</th></tr>
  <tr><td>A</td><td>120</td></tr>
  <tr><td>B</td><td>150</td></tr>
</table>
"""

soup = BeautifulSoup(html, "html.parser")
linhas = []
for tr in soup.find_all("tr")[1:]:
    tds = tr.find_all("td")
    linhas.append({"paciente": tds[0].text, "glicemia": int(tds[1].text)})
```

---

### 5.1.6 Boas pr√°ticas
- Respeite `robots.txt` e termos do site.  
- N√£o abuse: use `time.sleep(1)` entre requisi√ß√µes.  
- Prefira **APIs oficiais** quando houver.  
- Nunca colete dados pessoais (LGPD).  
- Salve o HTML original para reprodutibilidade.  

---

### 5.1.7 Erros comuns
- **`NoneType`**: seletor n√£o encontrou nada.  
- **Conte√∫do din√¢mico**: se for carregado via JS, BeautifulSoup n√£o v√™.  
- **Encoding errado**: for√ßar `resp.encoding = "utf-8"`.  
- **Seletores fr√°geis**: mudan√ßas no CSS do site podem quebrar o scraper.  

---

### 5.1.8 Exerc√≠cios ‚Äî BeautifulSoup

1. Extraia os **t√≠tulos das √∫ltimas not√≠cias** da OMS ([https://www.who.int/news](https://www.who.int/news)) e salve em CSV.  
2. No **PubMed**, busque ‚Äúdiabetes‚Äù (p√°gina HTML) e extraia t√≠tulos e links.  
3. Crie uma fun√ß√£o `get_links(html, seletor)` que retorna uma lista de URLs.  
4. Extraia uma **tabela cl√≠nica** de HTML fict√≠cio e converta para DataFrame.  
5. Crie `get_text_or_none(tag, sel)` que retorna texto ou `None`.  
6. Capture **manchetes e links** da se√ß√£o de Sa√∫de de um portal brasileiro.  
7. Adapte para lidar com **pagina√ß√£o** (`?page=1..N`).  
8. Salve resultados em **CSV** e **JSON** e explique diferen√ßas.  
9. Escreva **5 regras de √©tica em scraping** de sa√∫de e justifique.  
10. Mini-projeto: colete 10 not√≠cias da OMS, limpe duplicatas e exporte em `utf-8-sig`.  

---

## üîô Navega√ß√£o
- ‚¨ÖÔ∏è [Voltar ao Sum√°rio do Curso](../README.md)

